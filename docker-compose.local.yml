# Docker Compose for Local Testing and Docker Hub Deployment
# Optimized version with proper build contexts and health checks

version: '3.8'

services:
  # Redis cache service (shared by both systems)
  redis:
    image: redis:7-alpine
    container_name: ai-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - ai-network

  # ubiquitous-octo-invention (Conversation Intelligence)
  conversation-ai:
    build:
      context: ./ubiquitous-octo-invention
      dockerfile: Dockerfile.simple
    image: conversation-ai:latest
    container_name: conversation-ai
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - ENVIRONMENT=production
      - REDIS_URL=redis://redis:6379
      - PYTHONPATH=/app
      - LOG_LEVEL=info
      - DOCUMENT_SEARCH_URL=http://document-search:8000
      - ENABLE_DOCUMENT_SEARCH=true
    volumes:
      - conversation_logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - ai-network

  # ideal-octo-goggles (Document Search)
  document-search:
    build:
      context: ./ideal-octo-goggles
      dockerfile: Dockerfile.minimal
    image: document-search:latest
    container_name: document-search
    restart: unless-stopped
    ports:
      - "8080:8000"
    environment:
      - PYTHONUNBUFFERED=1
      - EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2
      - EMBEDDING_DIM=384
      - USE_GPU=false
      - INDEX_PATH=/app/indexes
      - REDIS_URL=redis://redis:6379
      - CONVERSATION_AI_URL=http://conversation-ai:8000
    volumes:
      - document_data:/app/data
      - document_indexes:/app/indexes
      - document_logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v2/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - ai-network

  # Nginx proxy for unified access
  nginx-proxy:
    image: nginx:alpine
    container_name: ai-nginx-proxy
    restart: unless-stopped
    ports:
      - "80:80"
    volumes:
      - ./nginx-unified.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      conversation-ai:
        condition: service_healthy
      document-search:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/status"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-network

  # Monitoring with Prometheus (optional)
  prometheus:
    image: prom/prometheus:latest
    container_name: ai-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    networks:
      - ai-network

volumes:
  redis_data:
    driver: local
  conversation_logs:
    driver: local
  document_data:
    driver: local
  document_indexes:
    driver: local
  document_logs:
    driver: local
  prometheus_data:
    driver: local

networks:
  ai-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/16
